{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_languages = [\n",
    "    \"Python\", \"JavaScript\", \"Java\", \"C#\", \"C++\", \"PHP\", \"Ruby\", \"Swift\",\n",
    "    \"Golang\", \"TypeScript\", \"R\", \"Kotlin\", \"HTML\", \"CSS\", \"SQL\", \"Rust\", \"Dart\",\n",
    "    \"Scala\", \"Perl\", \"Haskell\", \"Elixir\", \"Lua\", \"Bash\",\n",
    "    \"Objective-C\", \"Groovy\", \"F#\", \"Visual Basic\", \"MATLAB\", \"Assembly Language\",\n",
    "    \"Julia\", \"Cobol\", \"Fortran\", \"Erlang\", \"Prolog\", \"Crystal\", \"Tcl\", \"Lisp\",\n",
    "    \"ActionScript\", \"Apex\", \"Clojure\", \"Smalltalk\", \"Solidity\", \"NIM\", \n",
    "    \"OCaml\", \"Q#\", \"Ceylon\", \"VBScript\", \"Awk\", \"Racket\",\n",
    "    \"ABAP\", \"XSLT\", \"Lasso\", \"Max\", \"PostScript\", \n",
    "    \"Simulink\", \"Io\", \"Datalog\", \"Pliant\", \"J\", \"GAMS\", \"Gherkin\", \"SuperCollider\",\n",
    "    \"Sed\", \"PASCAL\"\n",
    "]\n",
    "\n",
    "for i in range(len(programming_languages)) :\n",
    "    if \".\" in programming_languages[i] :\n",
    "        programming_languages.append(programming_languages[i].replace(\".\",\"\"))\n",
    "\n",
    "databases = [\n",
    "    \"MySQL\",\n",
    "    \"PostgreSQL\",\n",
    "    \"SQLite\",\n",
    "    \"MongoDB\",\n",
    "    \"SQL Server\",\n",
    "    \"Oracle\",\n",
    "    \"Redis\",\n",
    "    \"Cassandra\",\n",
    "    \"MariaDB\",\n",
    "    \"DB2\",\n",
    "    \"Amazon DynamoDB\",\n",
    "    \"Firebase Realtime\",\n",
    "    \"Elasticsearch\",\n",
    "    \"Azure SQL\",\n",
    "    \"SAP HANA\",\n",
    "    \"CockroachDB\",\n",
    "    \"Google Cloud Firestore\",\n",
    "    \"Couchbase\",\n",
    "    \"Neo4j\",\n",
    "    \"HBase\",\n",
    "    \"Apache Hive\",\n",
    "    \"Teradata\",\n",
    "    \"Apache Cassandra\",\n",
    "    \"ArangoDB\",\n",
    "    \"RavenDB\",\n",
    "    \"Citus\",\n",
    "    \"TimescaleDB\",\n",
    "    \"OrientDB\",\n",
    "    \"Titan\",\n",
    "    \"TokuMX\",\n",
    "    \"VoltDB\",\n",
    "    \"Memcached\",\n",
    "    \"OpenTSDB\",\n",
    "    \"Dgraph\",\n",
    "    \"MarkLogic\",\n",
    "    \"Apache Drill\",\n",
    "    \"CouchDB\",\n",
    "    \"SAP IQ\",\n",
    "    \"NuoDB\",\n",
    "    \"Amazon Aurora\",\n",
    "    \"Azure Cosmos DB\",\n",
    "    \"CrateDB\",\n",
    "    \"Greenplum\",\n",
    "    \"Pivotal GemFire\",\n",
    "    \"EventStore\",\n",
    "    \"SQL Anywhere\",\n",
    "    \"DataStax Enterprise\",\n",
    "    \"AllegroGraph\",\n",
    "    \"Presto\",\n",
    "    \"Amazon Redshift\",\n",
    "    \"Informix\",\n",
    "    \"Apache Kudu\",\n",
    "    \"Sybase\",\n",
    "    \"Firebird\",\n",
    "    \"Apache Derby\",\n",
    "    \"SQLite\",\n",
    "    \"MaxDB\",\n",
    "    \"Teradata Aster\",\n",
    "    \"Vertica\",\n",
    "    \"Linterra\",\n",
    "    \"RocksDB\",\n",
    "    \"ClickHouse\",\n",
    "    \"Hadoop HDFS\",\n",
    "    \"Joomla\",\n",
    "    \"MSSQL\",\n",
    "    \"Xbase\",\n",
    "    \"Zebra\",\n",
    "    \"Wikidata\",\n",
    "    \"QlikView\",\n",
    "    \"Druid\",\n",
    "    \"Apache Phoenix\",\n",
    "    \"HSQLDB\",\n",
    "    \"Realm\",\n",
    "    \"CockroachDB\",\n",
    "    \"QLDB\",\n",
    "    \"Tarantool\",\n",
    "    \"Couchbase\",\n",
    "    \"Sphinx\",\n",
    "    \"InterBase\",\n",
    "    \"PouchDB\",\n",
    "    \"RavenDB\",\n",
    "    \"Pivotal Greenplum\",\n",
    "    \"TQL\",\n",
    "    \"Blazegraph\",\n",
    "    \"Netezza\",\n",
    "    \"Exasol\",\n",
    "    \"Coda\",\n",
    "    \"Qlik Sense\",\n",
    "    \"Linterra\",\n",
    "    \"Glean\",\n",
    "    \"OpenCensus\",\n",
    "    \"Snowflake\",\n",
    "    \"Metabase\"\n",
    "]\n",
    "for i in range(len(databases)) :\n",
    "    if \".\" in databases[i] :\n",
    "        print(databases[i])\n",
    "        databases.append(databases[i].replace(\".\",\"\"))\n",
    "\n",
    "frameworks = [\n",
    "    # Web Development\n",
    "    \"Kafka\",\n",
    "    \"SwiftUI\",\"Node.js\",\"React\", \"Angular\", \"Vue.js\", \"Django\", \"Flask\", \"Ruby on Rails\", \"Express.js\", \n",
    "    \"ASP.NET\", \"Spring\", \"Laravel\", \"Symfony\", \"FastAPI\", \"Svelte\", \"Backbone.js\", \n",
    "    \"CodeIgniter\", \"NestJS\", \"Meteor\", \"Pyramid\", \"Phoenix\", \n",
    "    \"Ionic\", \"Bootstrap\", \"Bulma\", \"Materialize\", \"Tailwind CSS\", \n",
    "    \"Ember.js\", \"Next.js\", \"Nuxt.js\", \"Gatsby\", \"Zope\", \"Sinatra\", \"JSP\", \n",
    "    \"Play Framework\", \"Tornado\", \"Web2py\", \"Sequelize\", \"Knex.js\", \"Deno\", \n",
    "    \"Sanity\", \"Strapi\", \"GraphQL\", \"RESTful API\", \"Jekyll\", \"Hugo\", \"Docusaurus\", \n",
    "    \"Aurelia\", \"Mithril\", \"Quasar\", \"Alpine.js\", \"Elm\", \"ClojureScript\", \n",
    "    \"PicoCMS\", \"Ant Design\", \"PrimeNG\", \"Semantic UI\", \"jQuery\", \n",
    "    \"Preact\", \"Turbo\", \"AppSync\", \"Flask-SocketIO\", \"Vapor\", \n",
    "    \"Jersey\", \"Vaadin\", \"Pico\", \"YII\", \"Tiki Wiki\", \"Phalcon\", \"Hapi.js\", \n",
    "    \"Koa.js\", \"Restify\", \"Slim\", \"Silex\", \"Liquid\", \"BootstrapVue\", \"Fomantic UI\", \n",
    "    \"Aurelia\", \"Chai\", \"Sass\", \"PostCSS\", \"jQuery UI\", \"Kendo UI\", \n",
    "    \"Dojo\", \"Webix\", \"Gijgo\", \"Pikaday\", \"FullCalendar\", \"Handsontable\", \n",
    "    \"GrapeJS\", \"Frappe\", \"Phabricator\", \"CakePHP\", \"Nette\", \"Yii2\", \"SilverStripe\", \n",
    "    \"OroCRM\", \"TYPO3\", \"CouchCMS\", \"Concrete5\", \"Grav\", \"Kirby\", \"OctoberCMS\", \n",
    "    \"ProcessWire\", \"MODX\", \"Craft CMS\", \"Pimcore\", \"Bolt\", \"Umbraco\", \"DotNetNuke\",\n",
    "\n",
    "    # Mobile Development\n",
    "    \"React Native\", \"Flutter\", \"Xamarin\", \"Ionic\", \"Apache Cordova\", \"USwiftI\", \n",
    "    \"Kotlin Multiplatform Mobile\", \"PhoneGap\", \"NativeScript\", \"Sencha Touch\", \n",
    "    \"Appcelerator Titanium\", \"Framework7\", \"Unity\", \"Cocos2d-x\", \"Fusetools\", \n",
    "    \"NativeBase\", \"Quasar Framework\", \"Onsen UI\", \"Cordova\", \"ReactXP\", \n",
    "    \"Tauri\", \"Kivy\", \"PyQt5\", \"wxPython\", \"BeeWare\", \"Gluon\", \"Crosswalk\", \n",
    "    \"Fyn\", \"Material Components for Android\", \"Robolectric\", \"Apache Felix\", \n",
    "    \"Zygote\", \"UI Automator\", \"MonkeyRunner\", \"Firebase UI\", \"Codename One\", \n",
    "    \"Nativescript-Vue\", \"RxJava\", \"Dagger\", \"ButterKnife\", \"Retrofit\", \"Volley\", \n",
    "    \"OkHttp\", \"RxAndroid\", \"Firebase Cloud Messaging\", \"Fastlane\", \"Swift Package Manager\",\n",
    "\n",
    "    # Game Development\n",
    "    \"Unity\", \"Unreal Engine\", \"Godot\", \"Cocos2d\", \"CryEngine\", \"GameMaker Studio\", \n",
    "    \"Phaser\", \"LibGDX\", \"Defold\", \"Ren'Py\", \"SpriteKit\", \"Cocos2d-x\", \n",
    "    \"Pygame\", \"MonoGame\", \"JMonkeyEngine\", \"GameSalad\", \"Havok\", \"Fmod\", \"Unity3D\", \n",
    "    \"CryEngine\", \"Torque3D\", \"PlayCanvas\", \"Blend4Web\", \"Panda3D\", \"CopperLicht\", \n",
    "    \"Ogre3D\", \"Three.js\", \"Babylon.js\", \"Fusio\", \"LÖVE\", \"BGE\", \"Cinder\", \n",
    "    \"Game Framework\", \"Wave Engine\", \"PICO-8\", \"Phaser Editor\", \"GDevelop\", \n",
    "    \"Cocos Creator\", \"Chocolat\", \"Bevy\", \"Flixel\", \"Luxe\", \"Leadwerks\", \n",
    "    \"Allegro\", \"GML\", \"Squirrel\", \"Visual3D\", \"Sunburn\", \"C4\", \"Zenject\",\n",
    "\n",
    "    # Data Science and Machine Learning\n",
    "    \"PySpark\",\"Tensorflow\", \"Keras\", \"PyTorch\", \"Scikit\", \"Pandas\", \"NumPy\", \n",
    "    \"Matplotlib\", \"Seaborn\", \"Spark\", \"Dask\", \"H2O.ai\", \"Apache Flink\", \n",
    "    \"Hadoop\", \"OpenCV\", \"NLTK\", \"spaCy\", \"FastAI\", \"XGBoost\", \"LightGBM\", \n",
    "    \"CatBoost\", \"MLflow\", \"Airflow\", \"PyCaret\", \"Dask-ML\", \"Haystack\", \n",
    "    \"Shiny\", \"Dash\", \"Plotly\", \"Streamlit\", \"Bokeh\", \"TensorBoard\", \n",
    "    \"Chainer\", \"Pytorch Lightning\", \"TPOT\", \"DataRobot\", \"AutoML\", \"TPOT\", \n",
    "    \"Optuna\", \"Ray\", \"FastText\", \"gensim\", \"Featuretools\", \"Weka\", \n",
    "    \"KNIME\", \"Alteryx\", \"Datarobot\", \"Metaflow\", \"Jupyter Notebook\", \n",
    "     \"Dash\", \"Orange3\", \"DeepSpeed\", \"Fairlearn\", \"FiftyOne\",\n",
    "\n",
    "    # DevOps and CI/CD\n",
    "     \"Babel\",\"Vite\",\"Parcel\",\"Webpack\",\"Grunt\",\n",
    "\n",
    "    # Testing Frameworks\n",
    "    \"JUnit\", \"pytest\", \"Selenium\", \"Mocha\", \"Chai\", \"Jasmine\", \"Cypress\", \n",
    "    \"TestNG\", \"RSpec\", \"Jest\", \"Karma\", \"Puppeteer\", \"Robot Framework\", \n",
    "    \"Protractor\", \"Postman\", \"Cucumber\", \"JUnit\", \"NUnit\", \"Vitest\", \n",
    "    \"Enzyme\", \"Cypress\", \"Supertest\", \"Mocha\", \"Mochawesome\", \"Pytest-bdd\", \n",
    "    \"Gatling\", \"Locust\", \"Trestle\", \"Avro\", \"WireMock\", \"Karate\", \n",
    "    \"Selenium Grid\", \"Applitools\", \"Gauge\", \"Cypress\", \"RestAssured\", \n",
    "    \"Flask-Testing\", \"Flask-RESTPlus\", \"Playwright\", \"SpecFlow\", \"Codacy\", \n",
    "    \"SonarQube\", \"Selenium IDE\",\n",
    "\n",
    "    # Desktop Applications\n",
    "    \"Electron\", \"Qt\", \"GTK\", \"JavaFX\", \"wxWidgets\", \"Avalonia\", \"Flutter Desktop\", \n",
    "    \"Nw.js\", \"Xamarin.Forms\", \"React Native Windows\", \"Tauri\", \"Electron Forge\", \n",
    "    \"PyQt\", \"Tkinter\", \"Kivy\", \"PySide\", \"WinForms\", \"MFC\", \"GTK\", \"UWP\", \n",
    "    \"Avalonia UI\", \"JavaFX\", \"Flutter\", \"Blazor\", \"Uno Platform\", \"WPF\", \n",
    "    \"Chocolat\", \"AppKit\", \"Mac Catalyst\", \"PyQt5\", \"Gnome\", \"Electron React\", \n",
    "    \"Cocoa\", \"Xamarin\", \"Delphi\", \"Qt Creator\", \"QT Quick\", \"Swing\", \n",
    "    \"Java Swing\", \"Pygame\", \"Avalonia\", \"VCL\",\n",
    "\n",
    "    # Other Frameworks and Libraries\n",
    "\n",
    "    \"FAIR\",\"KOBIT\", \"RabbitMQ\", \"Celery\", \"OpenShift\", \"Nginx\", \"Apache HTTP Server\" , \"SendGrid\", \"Twilio\", \"Stripe\", \"Socket.io\", \n",
    "    \"GraphQL\", \"gRPC\", \"Pusher\", \"Flask-RESTful\", \n",
    "    \"Jupyter Notebook\", \"Apache Thrift\", \"Hapi.js\", \"React Query\", \"Apollo Client\", \n",
    "    \"WebAssembly\", \"RxJS\", \"Flux\", \"MobX\", \"Gulp\", \"Webpack\", \"Parcel\", \n",
    "    \"Babel\", \"Grunt\", \"Vite\", \"Puppeteer\", \"Sass\", \"PostCSS\", \"Frappe\", \"Django REST Framework\", \"Netty\", \n",
    "    \"Spring Boot\", \"Play Framework\", \"Dropwizard\", \"Java EE\", \"Vaadin\", \n",
    "    \"Grails\", \"Avert\", \"Flyway\", \"JOOQ\", \"Spring Data\", \"MicroProfile\", \n",
    "    \"Ktor\", \"Vert.x\", \"Gson\", \"Jackson\", \"jOOQ\", \"Apache Ant\", \"Jenkins\", \n",
    "    \"Concourse\", \"Mercurial\", \"Bazaar\", \n",
    "    \"TFS\", \"Subversion\", \"Plastic SCM\", \"FogBugz\", \"Phabricator\", \"Helix Core\", \n",
    "    \"Gitea\", \"Gogs\", \"SourceGear Vault\", \"SmartSVN\", \"TortoiseSVN\", \n",
    "    \"Fossil\", \"SVN\", \"Aegis\",\n",
    "\n",
    "    # Additional Frameworks\n",
    "    \"ISO 27001\",\n",
    "\"MITRE ATT\",\n",
    "\"COBIT\",\n",
    "\"PCI DSS\",\n",
    "\"SOC 2\",\n",
    "\"GDPR\",\n",
    "\"ITIL\",\n",
    "\"CMMI\",\n",
    "\"Cis Controls\",\n",
    "    \"Spring Cloud\", \"Spring Security\", \"Spring MVC\", \"Spring Integration\", \n",
    "    \"Spring Batch\", \"Apache Camel\", \"Apache Shiro\", \"Canoe\", \"Libuv\", \n",
    "    \"ASP.NET MVC\", \"ASP.NET Core\", \"Apache Cordova\", \"Xamarin\", \"OSGi\", \n",
    "    \"React Query\", \"SWR\", \"Apollo Client\", \"Puppeteer\", \"Cheerio\", \n",
    "    \"Bootstrap\", \"Fomantic UI\", \"Materialize\", \"PrimeReact\", \n",
    "    \"Ant Design\", \"Semantic UI\", \"Spectre.css\", \"UIKit\", \"Material Design Lite\", \n",
    "    \"Milligram\", \"Skeleton\", \"Blaze UI\", \"Fomantic UI\", \"Semantic UI React\", \n",
    "    \"Stylus\", \"Foundation Sites\", \"HTML5 Boilerplate\", \"Normalize.css\", \n",
    "    \"PostCSS\", \"CSS Modules\", \"CSS-in-JS\", \"Styled Components\", \n",
    "    \"Emotion\", \"JSS\", \"Radium\", \"Shadow DOM\", \"LitElement\", \"HyperHTML\", \n",
    "    \"html.js\", \"Gatsby\", \"Next.js\", \"Nuxt.js\", \"Hugo\", \"Jekyll\", \"Docusaurus\", \n",
    "    \"Scully\", \"Sapper\", \"Gatsby\", \"Middleman\", \"Grunt\", \"Gulp\", \"npm\", \n",
    "    \"Yarn\", \"Webpack\", \"Parcel\", \"Vite\", \"Fly\", \"Zola\", \"Ziggy\", \"TiddlyWiki\", \n",
    "    \"Sphinx\", \"MkDocs\", \"Doxygen\", \"HDoc\", \"Doxygen\", \n",
    "    \"Javadoc\", \"Sphinx\", \"Hugo\", \"Jekyll\", \"MkDocs\"\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(len(frameworks)) :\n",
    "    if \".\" in frameworks[i] :\n",
    "        frameworks.append(frameworks[i].replace(\".\",\"\"))\n",
    "\n",
    "\n",
    "cloud_service_providers = [\n",
    "    \"Bigquery\",\n",
    "    \"Redshift\",\n",
    "    \"Databricks\",\n",
    "    \"AWS\",\n",
    "    \"Azure\",\n",
    "    \"GCP\",\n",
    "    \"IBM Cloud\",\n",
    "    \"Oracle Cloud\",\n",
    "    \"Salesforce\",\n",
    "    \"DigitalOcean\",\n",
    "    \"Linode\",\n",
    "    \"Vultr\",\n",
    "    \"Heroku\",\n",
    "    \"Rackspace\",\n",
    "    \"Cloudflare\",\n",
    "    \"Red Hat OpenShift\",\n",
    "    \"SAP Cloud Platform\",\n",
    "    \"Alibaba Cloud\",\n",
    "    \"Mendix\",\n",
    "    \"Cisco Cloud\",\n",
    "    \"Cloudways\",\n",
    "    \"Trello\",\n",
    "    \"Zoho\",\n",
    "    \"Atlassian Cloud\",\n",
    "    \"Smartsheet\",\n",
    "    \"Firebase\",\n",
    "    \"Contentful\",\n",
    "    \"Shopify\",\n",
    "    \"Zendesk\",\n",
    "    \"Fastly\",\n",
    "    \"Akamai\",\n",
    "    \"SiteGround\",\n",
    "    \"InMotion Hosting\",\n",
    "    \"WP Engine\",\n",
    "    \"GreenGeeks\",\n",
    "    \"A2 Hosting\",\n",
    "    \"HostGator\",\n",
    "    \"iPage\",\n",
    "    \"Bluehost\",\n",
    "    \"Liquid Web\",\n",
    "    \"DreamHost\",\n",
    "    \"Kinsta\",\n",
    "    \"CloudSigma\",\n",
    "    \"OVHcloud\",\n",
    "    \"CenturyLink Cloud\",\n",
    "    \"Gandi\",\n",
    "    \"Google Workspace\",\n",
    "    \"Microsoft 365\",\n",
    "    \"MaxCompute\",\n",
    "    \"Clever Cloud\",\n",
    "    \"Render\",\n",
    "    \"Platform.sh\",\n",
    "    \"Back4App\",\n",
    "    \"Kinvey\",\n",
    "    \"GCP Firebase\",\n",
    "    \"Bitbucket\",\n",
    "    \"Vercel\",\n",
    "    \"Netlify\",\n",
    "    \"Glitch\",\n",
    "    \"Heroku Postgres\",\n",
    "    \"Linode Block Storage\",\n",
    "    \"Cloudian\",\n",
    "    \"Pivotal Cloud Foundry\",\n",
    "    \"Couchbase Cloud\",\n",
    "    \"MongoDB Atlas\",\n",
    "    \"BaaS\",\n",
    "    \"Auth0\",\n",
    "    \"Cloudflare Workers\",\n",
    "    \"Kinsta Managed WordPress Hosting\",\n",
    "    \"Elastic Cloud\",\n",
    "    \"Integromat\",\n",
    "    \"Zapier\",\n",
    "    \"Cognito\",\n",
    "    \"S3\",\n",
    "    \"Oracle Cloud Infrastructure\",\n",
    "    \"IBM Watson\",\n",
    "    \"Azure DevOps\",\n",
    "    \"CloudStack\",\n",
    "    \"OpenStack\",\n",
    "    \"Scaleway\",\n",
    "    \"Jelastic\",\n",
    "    \"Backblaze B2\",\n",
    "    \"Linode Kubernetes Engine\",\n",
    "    \"Miro\",\n",
    "    \"Airtable\",\n",
    "    \"Quip\",\n",
    "    \"SurveyMonkey\",\n",
    "    \"Slack\",\n",
    "    \"Sentry\",\n",
    "    \"AppDynamics\",\n",
    "    \"New Relic\",\n",
    "    \"Grafana Cloud\",\n",
    "    \"Prometheus\",\n",
    "    \"CloudHealth\",\n",
    "    \"SaaSOptics\",\n",
    "    \"Zoho One\",\n",
    "    \"FreshBooks\",\n",
    "    \"Xero\",\n",
    "    \"QuickBooks Online\",\n",
    "    \"Wix\",\n",
    "    \"Webflow\",\n",
    "    \"Shopify Plus\",\n",
    "    \"BigCommerce\",\n",
    "    \"Adobe Experience Cloud\",\n",
    "    \"Veeva Vault\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "other_tools = [\n",
    "    \"Owasp\",\n",
    "    \"Zscaler\", \n",
    "    \"CrowdStrike\", \n",
    "    \"Rapid7\", \n",
    "    \"Defender VM\", \n",
    "    \"Qualys\", \n",
    "    \"Tenable\", \n",
    "    \"Nessus\", \n",
    "    \"Auth0\", \n",
    "    \"PingID\", \n",
    "    \"Azure AD\", \n",
    "    \"Okta\",\n",
    "    \"Cisco\",\"SSIS\",\n",
    "    \"Ansible\", \"Terraform\", \"Jenkins\", \"CircleCI\", \n",
    "    \"Travis CI\", \"GitLab CI\", \"AWS CodePipeline\", \"Chef\", \n",
    "    \"Puppet\", \"Octopus Deploy\", \"Helm\", \"Grafana\", \"Nagios\", \n",
    "    \"Datadog\", \"ELK Stack\", \"Kibana\", \n",
    "    \"GitHub Actions\", \"AppVeyor\", \"Codacy\", \"Tecton\", \"LaunchDarkly\", \n",
    "    \"Semaphore\", \"GitKraken\", \"Azure DevOps Server\", \"GitHub Pages\", \"Render\", \"Fly.io\", \n",
    "    \"Railway\", \"npm\", \"Yarn\", \"Composer\", \"Bower\", \"Gulp\", \n",
    "    \"Webpack\", \"Parcel\", \"Babel\", \"Grunt\", \"Vite\", \"Sentry\", \"SonarQube\",\"Kubernetes\",\"CVS\",\"Wordpress\",\"Apache Superset\",'SAS','Docker','QRadar', 'Securonix',\n",
    "       'Checkpoint', 'FireEye', 'ArcSight',\n",
    "       'NIST Cybersecurity Framework', 'Nessus', 'Wireshark',\n",
    "       'Palo Alto Networks', 'Burp Suite', 'Kali Linux', 'Trend Micro',\n",
    "       'Sophos', 'Responder', 'Metasploit', 'Nmap', 'Cisco ASA',\n",
    "    \"Qualys\",\n",
    "    \"Splunk\",\n",
    "    \"DataStage\",\n",
    "    \"spotfire\",\n",
    "    \"sap\",\n",
    "    \"Git\",\n",
    "    \"Office Suite\",\n",
    "    \"Trello\",\n",
    "    \"Asana\",\n",
    "    \"Jira\",\n",
    "    \"Confluence\",\n",
    "    \"Zoom\",\n",
    "    \"Adobe Creative Cloud\",\n",
    "    \"Figma\",\n",
    "    \"Canva\",\n",
    "    \"Miro\",\n",
    "    \"Power BI\",\n",
    "    \"Notion\",\n",
    "    \"Monday.com\",\n",
    "    \"Dropbox\",\n",
    "    \"Box\",\n",
    "    \"SharePoint\",\n",
    "    \"Evernote\",\n",
    "    \"GitHub\",\n",
    "    \"HubSpot\",\n",
    "    \"Mailchimp\",\n",
    "    \"Zapier\",\n",
    "    \"QuickBooks\",\n",
    "    \"Toggl\",\n",
    "    \"LastPass\",\n",
    "    \"Tableau\",\n",
    "    \"Google Analytics\",\n",
    "    \"SEMrush\",\n",
    "    \"JotForm\",\n",
    "    \"Basecamp\",\n",
    "    \"ClickUp\",\n",
    "    \"InVision\",\n",
    "    \"Lucidchart\",\n",
    "    \"Visio\",\n",
    "    \"PowerPoint\",\n",
    "    \"Google Slides\",\n",
    "    \"Balsamiq\",\n",
    "    \"MindMeister\",\n",
    "    \"XMind\",\n",
    "    \"Calendly\",\n",
    "    \"RescueTime\",\n",
    "    \"Adobe Acrobat\",\n",
    "    \"Mendeley\",\n",
    "    \"EndNote\",\n",
    "    \"Excel\",\n",
    "    \"Adobe Analytics\",\n",
    "    \"Looker\",\n",
    "    \"Adobe Creative Suite\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(i,word_array):\n",
    "  try:\n",
    "    for j in range (i-5,i):\n",
    "        if word_array[j]== \"year\" or word_array[j]==\"years\":\n",
    "          return j\n",
    "  except:\n",
    "    return -1\n",
    "\n",
    "  return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "  word_array = text.split()\n",
    "  for i in range(len(word_array)) :\n",
    "    if word_array[i] == \"experience\" or word_array[i]==\"experiences\":\n",
    "      j=in_range(i,word_array)\n",
    "      if j != -1:\n",
    "        return word_array[j-1]\n",
    "  return \"Not_specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text,skillset):\n",
    "    skills = []\n",
    "    for i in skillset :\n",
    "      if i.lower() in text.lower():\n",
    "        skills.append(i)\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_extractor(programming_languages,frameworks,databases,cloud_service_providers,other_tools,job_requirements,experiences):\n",
    "  # Load the HTML content\n",
    "  with open(f'C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_glassdoor.html', 'r', encoding='utf-8') as file:\n",
    "      html_content = file.read()\n",
    "\n",
    "  soup = BeautifulSoup(html_content, 'html.parser')\n",
    "  skills = programming_languages + frameworks + databases + cloud_service_providers + other_tools\n",
    "  skills = list(set(skills))\n",
    "  \n",
    "  for i in range (len(skills)) :\n",
    "    if len(skills[i])<=10:\n",
    "      skills[i]=\" \"+skills[i]+\" \"\n",
    "\n",
    "  text_array = []\n",
    "  brandviews_div = soup.find('div', attrs={'data-brandviews': True})\n",
    "    \n",
    "  if brandviews_div:\n",
    "      # Extract <li> and <p> tags only from the found <div>\n",
    "      li_tags = brandviews_div.find_all('li', class_=False)\n",
    "      p_tags = brandviews_div.find_all('p', class_=False)\n",
    "\n",
    "      for i in li_tags:\n",
    "          text_array.append(i.text)\n",
    "\n",
    "      for i in p_tags:\n",
    "          text_array.append(i.text)\n",
    "\n",
    "  concatenated_string = \" \".join(text_array)\n",
    "\n",
    "  concatenated_string = \" \"+concatenated_string+\" \"\n",
    "  concatenated_string = re.sub(r'(?<![A-Za-z0-9])\\.|\\.(?![A-Za-z0-9])|[^A-Za-z0-9.#+]', ' ', concatenated_string)\n",
    "\n",
    "  print(concatenated_string)\n",
    "  #print(extract_skills(concatenated_string,skills))\n",
    "\n",
    "  #job_requirements.append(concatenated_string)\n",
    "  #experiences.append(extract_experience(concatenated_string))\n",
    "\n",
    "\n",
    "  #return (extract_skills(concatenated_string,skills))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_close_login_modal():\n",
    "    try:\n",
    "        close_button = wd.find_element(By.CLASS_NAME, \"CloseButton\")\n",
    "        close_button.click()\n",
    "        print(\"Login modal closed.\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"No login modal appeared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info():\n",
    "    with open('C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_glassdoor.html', 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    # Find all divs with the specified class\n",
    "    divs = soup.find_all('div', class_='EmployerProfile_profileContainer__63w3R EmployerProfile_compact__28h9t')\n",
    "    Id_array=[]\n",
    "    company_name=[]\n",
    "\n",
    "    for div in divs:\n",
    "        div_id = div.get('id')  # Extract the id attribute\n",
    "        #print(f\"ID: {div_id}\")  # Print the ID\n",
    "        Id_array.append(div_id)\n",
    "        #print(div.text)  # Print the text content of each div\n",
    "        company_name.append(div.text)\n",
    "\n",
    "    job_links = []\n",
    "\n",
    "    for job_card in soup.find_all('li', {'data-test': 'jobListing'}):\n",
    "        link = job_card.find('a', {'data-test': 'job-link'})\n",
    "        age = job_card.find('div', {'data-test': 'job-age'})\n",
    "        \n",
    "        if link and age:\n",
    "            job_links.append(link['href'])  # Get the href attribute\n",
    "            #job_ages.append(age.text.strip())\n",
    "    \n",
    "    job_cards = soup.find_all('div', class_='JobCard_jobCardContainer__arQlW') #if the html code changes search detalSalary in the inspect mode and get the new class name\n",
    "    \n",
    "    title=[]\n",
    "    location=[]\n",
    "    salary=[]\n",
    "    employer=[]\n",
    "    rating=[]\n",
    "\n",
    "    job_dataframe = []\n",
    "\n",
    "    i=0\n",
    "    # Extract relevant information from each job card\n",
    "    for job_card in job_cards:\n",
    "        # Extract job title\n",
    "        job_title = job_card.find('a', class_='JobCard_jobTitle__GLyJ1').text.strip() if job_card.find('a', class_='JobCard_jobTitle__GLyJ1') else \"N/A\"\n",
    "        title.append(job_title)\n",
    "\n",
    "        # Extract job location\n",
    "        job_location = job_card.find('div', class_='JobCard_location__Ds1fM').text.strip() if job_card.find('div', class_='JobCard_location__Ds1fM') else \"N/A\"\n",
    "        location.append(job_location)\n",
    "\n",
    "        # Extract salary estimate\n",
    "        job_salary = job_card.find('div', class_='JobCard_salaryEstimate__QpbTW').text.strip() if job_card.find('div', class_='JobCard_salaryEstimate__QpbTW') else \"N/A\"\n",
    "        salary.append(job_salary)\n",
    "\n",
    "        # Extract employer name\n",
    "        employer_name = job_card.find('span', class_='EmployerProfile_compactEmployerName__9MGcV').text.strip() if job_card.find('span', class_='EmployerProfile_compactEmployerName__9MGcV') else \"N/A\"\n",
    "        employer.append(employer_name)\n",
    "\n",
    "        # Extract employer rating\n",
    "        employer_rating = job_card.find('span', class_='EmployerProfile_ratingContainer__ul0Ef').text.strip() if job_card.find('span', class_='EmployerProfile_ratingContainer__ul0Ef') else \"N/A\"\n",
    "        #rating.append(employer_rating)\n",
    "        rating.append(None)\n",
    "\n",
    "        '''\n",
    "        # Print the extracted information\n",
    "        print(f\"Job Title: {job_title}\")\n",
    "        print(f\"Job ID: {Id_array[i]}\")\n",
    "        print(f\"Company Name : {company_name[i]}\")\n",
    "        print(f\"Location: {job_location}\")\n",
    "        print(f\"Salary: {job_salary}\")\n",
    "        print(f\"Employer: {employer_name}\")\n",
    "        print(f\"Rating: {employer_rating}\")\n",
    "        print(f\"Link : {job_links[i]}\")\n",
    "        print('-' * 40)\n",
    "        '''\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    print(f\"Length of Id_array: {len(Id_array)}\")\n",
    "    print(f\"Length of title: {len(title)}\")\n",
    "    print(f\"Length of company_name: {len(company_name)}\")\n",
    "    print(f\"Length of location: {len(location)}\")\n",
    "    print(f\"Length of salary: {len(salary)}\")\n",
    "    print(f\"Length of employer: {len(employer)}\")\n",
    "    print(f\"Length of job_links: {len(job_links)}\")\n",
    "\n",
    "            \n",
    "    temp_df=pd.DataFrame({\n",
    "    \"Job ID\": Id_array,  # Ensure Id_array is defined and populated\n",
    "    \"Job Title\": title,\n",
    "    \"Company Name\": company_name,  # Ensure company_name is defined and populated\n",
    "    \"Location\": location,\n",
    "    \"Salary\": salary,\n",
    "    \"Employer\": employer,\n",
    "    \"Rating\": employer,\n",
    "    \"Link\": job_links,\n",
    "    })\n",
    "\n",
    "    job_dataframe.append(temp_df)\n",
    "        \n",
    "    df=pd.concat(job_dataframe)\n",
    "    return df\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = \"C:\\\\Users\\\\ahmad\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-21nov24\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=3\n",
    "base_url=[\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-data-analyst-jobs-SRCH_IL.0,8_IN170_KO9,21.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-data-scientists-jobs-SRCH_IL.0,8_IN170_KO9,24.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-data-engineer-jobs-SRCH_IL.0,8_IN170_KO9,22.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-full-stack-developer-jobs-SRCH_IL.0,12_IC2986682_KO13,33.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-front-end-developer-jobs-SRCH_IL.0,8_IN170_KO9,28.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-backend-developer-jobs-SRCH_IL.0,12_IC2986682_KO13,30.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-cloud-engineer-jobs-SRCH_IL.0,8_IN170_KO9,23.htm?fromAge={days}\",\n",
    "    f\"https://www.glassdoor.com/Job/malaysia-business-analyst-jobs-SRCH_IL.0,8_IN170_KO9,25.htm?fromAge={days}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=driver_path)\n",
    "\n",
    "wd = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes=[]\n",
    "for a in range (len(base_url)):  \n",
    "    wd.get(base_url[a])\n",
    "    with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_glassdoor.html\", \"w\") as file:\n",
    "            file.write(wd.page_source)\n",
    "\n",
    "    with open('C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_glassdoor.html', 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "\n",
    "    job_titles = soup.find_all('h1', {'data-test': 'search-title'})\n",
    "    str_=job_titles[0].text.strip()\n",
    "    number_of_jobs = re.sub(r'\\D', '', str_)\n",
    "    number_of_jobs = int(number_of_jobs)\n",
    "\n",
    "    number_of_pages = int(number_of_jobs/30)\n",
    "    if(number_of_pages==0):\n",
    "         number_of_pages=1\n",
    "    print(\"Number of jobs : \",number_of_jobs)\n",
    "    print(\"Number of pages : \",number_of_pages)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Click the 'Show More Jobs' button 3 times\n",
    "    for _ in range(number_of_pages):\n",
    "        # Check for the login modal before clicking\n",
    "        check_and_close_login_modal()\n",
    "\n",
    "        try:\n",
    "            load_more_button = wd.find_element(By.CSS_SELECTOR, 'button[data-test=\"load-more\"]')\n",
    "            \n",
    "            # Click the button to load more jobs\n",
    "            load_more_button.click()\n",
    "            \n",
    "            # Wait for the new jobs to load after the button click\n",
    "            time.sleep(5)\n",
    "            \n",
    "            print(\"Clicked 'Show more jobs' button.\")\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            print(\"No 'Show more jobs' button found.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    # Save the updated page source\n",
    "    with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_glassdoor.html\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(wd.page_source)\n",
    "    df=get_info()\n",
    "    dataframes.append(df)\n",
    "    wd.quit()\n",
    "    wd = webdriver.Chrome(service=service)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(dataframes)\n",
    "#df.to_csv(\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\WebScraping101\\\\temp_glassdoor data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "job_requirements=[]\n",
    "year_of_experiences=[]\n",
    "skills_col=[]\n",
    "\n",
    "n=0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (len(df)):\n",
    "    try:\n",
    "        wd.quit()\n",
    "        wd = webdriver.Chrome(service=service)\n",
    "        wd.get(f\"https://www.glassdoor.com{df.iloc[i][\"Link\"]}\")\n",
    "        print(f\"{i+1}.Link : \",df.iloc[i][\"Link\"])\n",
    "        with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_glassdoor.html\", \"w\") as file:\n",
    "                file.write(wd.page_source)\n",
    "\n",
    "        #skill_extractor(programming_languages,frameworks,databases,cloud_service_providers,other_tools,job_requirements,year_of_experiences)\n",
    "        \n",
    "        with open('C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_glassdoor.html', 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "        divs = soup.find_all('div', attrs={'data-brandviews': True})\n",
    "\n",
    "        text_array=[]\n",
    "\n",
    "        # Check if there is at least one div found\n",
    "        if divs:\n",
    "            skills = programming_languages + frameworks + databases + cloud_service_providers + other_tools\n",
    "            skills = list(set(skills))\n",
    "            \n",
    "\n",
    "            for j in range (len(skills)) :\n",
    "                if len(skills[j])<=10:\n",
    "                    skills[j]=\" \"+skills[j]+\" \"\n",
    "\n",
    "\n",
    "            first_div = divs[0]  # Get the first div\n",
    "            \n",
    "            # Extract and print all <p> and <li> tags from the first <div>\n",
    "            if first_div.find('p') or first_div.find('li'):  # Check if it contains <p> or <li>\n",
    "                # Extract all <p> tags\n",
    "                p_tags = first_div.find_all('p')\n",
    "                for p in p_tags:\n",
    "                    #print(p.get_text(strip=True))  # Print only the text\n",
    "                    text_array.append(p.get_text(strip=True))\n",
    "\n",
    "                # Extract all <li> tags\n",
    "                li_tags = first_div.find_all('li')\n",
    "                for li in li_tags:\n",
    "                    text_array.append(li.get_text(strip=True))\n",
    "                    #print(li.get_text(strip=True))  # Print only the text\n",
    "\n",
    "            concatenated_string = \" \".join(text_array)\n",
    "            concatenated_string = \" \"+concatenated_string+\" \"\n",
    "            concatenated_string = re.sub(r'(?<![A-Za-z0-9])\\.|\\.(?![A-Za-z0-9])|[^A-Za-z0-9.#+]', ' ', concatenated_string)\n",
    "            #print(text_array)\n",
    "            print(concatenated_string)\n",
    "\n",
    "\n",
    "\n",
    "            skills_needed=extract_skills(concatenated_string,skills)\n",
    "            experience=extract_experience(concatenated_string)\n",
    "\n",
    "            job_requirements.append(concatenated_string)\n",
    "            year_of_experiences.append(experience)\n",
    "            skills_col.append(skills_needed)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"skills:\",skills_needed)\n",
    "            print(\"experience:\",experience)\n",
    "            print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "            \n",
    "        else:\n",
    "            job_requirements.append(\"error\")\n",
    "            error_arr=[]\n",
    "            skills_col.append(error_arr)\n",
    "            year_of_experiences.append(\"error\")\n",
    "\n",
    "            print(\"No divs found with the specified attribute.\")\n",
    "\n",
    "    except Exception :\n",
    "        job_requirements.append(\"error\")\n",
    "        error_arr=[]\n",
    "        skills_col.append(error_arr)\n",
    "        year_of_experiences.append(\"error\")\n",
    "        print(\"An error occured during scraping.\")\n",
    "\n",
    "    #if(i>3):\n",
    "       # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.quit()\n",
    "print(\"Length of job_requirements:\", len(job_requirements))\n",
    "print(\"Length of skills_col:\", len(skills_col))\n",
    "print(\"Length of year_of_experiences:\", len(year_of_experiences))\n",
    "print(\"Length of DataFrame index:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(len(job_requirements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Job Requirements\"]=job_requirements\n",
    "df[\"Skills\"]=skills_col\n",
    "df[\"Experience\"]=year_of_experiences\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\WebScraping101\\\\business_analyst_glassdoor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_internship(row):\n",
    "    if (\"intern\" in row[\"Job Title\"].lower()) :\n",
    "        return \"Internship\"\n",
    "    else :\n",
    "        return row[\"Experience\"]\n",
    "\n",
    "df_1 = df.copy()\n",
    "\n",
    "df_1[\"Experience_new\"]= df_1.apply( det_internship, axis=1)\n",
    "df_1.drop(columns=[\"Experience\"],inplace=True)\n",
    "df_1.rename(columns={\"Experience_new\":\"Experience\"},inplace=True)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2.drop(columns=[\"Employer\",\"Rating\",\"Link\"],inplace=True)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dup(job_id):\n",
    "    return df_3[\"Job ID\"].value_counts().get(job_id, 0) > 1\n",
    "\n",
    "def det_condition(rows):\n",
    "    if(has_dup(rows[\"Job ID\"]) and rows[\"Job Requirements\"]==\"error\"):\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "\n",
    "#**Removing duplicates**\n",
    "print(\"Number of unique jobs : \",len(df_2[\"Job ID\"].unique()))\n",
    "df_3=df_2.copy()\n",
    "df_3['condition']=df_3.apply(det_condition,axis=1)\n",
    "df_3=df_3[df_3['condition']==False]\n",
    "df_3.drop(columns = [\"condition\"],inplace=True)\n",
    "df_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "df_4 = df_4.drop_duplicates(subset=[\"Job ID\"])\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a short job title column\n",
    "short_job=[]\n",
    "for index,rows in df_4.iterrows():\n",
    "    if \"data\" in rows[\"Job Title\"].lower() and \"scien\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Scientist\")\n",
    "    elif \"business\" in rows[\"Job Title\"].lower() and (\"anal\" in rows[\"Job Title\"].lower() or \"intell\" in rows[\"Job Title\"].lower()):\n",
    "        short_job.append(\"Business Analyst\")\n",
    "    elif \"data\" in rows[\"Job Title\"].lower() and \"engine\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Engineer\")\n",
    "    elif \"data\" in rows[\"Job Title\"].lower() and \"anal\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Analyst\")\n",
    "    elif \"machine\" in rows[\"Job Title\"].lower() and \"learn\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Scientist\")\n",
    "    elif \"full\" in rows[\"Job Title\"].lower() and \"stack\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append('Full Stack Developer')\n",
    "    elif \"back\" in rows[\"Job Title\"].lower() and \"end\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Backend Developer\")\n",
    "    elif \"front\" in rows[\"Job Title\"].lower() and \"end\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Frontend Developer\")\n",
    "    elif \"software\" in rows[\"Job Title\"].lower() and (\"engine\" in rows[\"Job Title\"].lower() or \"develop\" in rows[\"Job Title\"].lower()):\n",
    "        short_job.append(\"Developer\")\n",
    "    elif \"developer\" in rows[\"Job Title\"].lower() or \"programmer\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Developer\")\n",
    "    elif \"cloud\" in rows[\"Job Title\"].lower() or \"devop\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Cloud Engineer\")\n",
    "    elif \"secu\" in rows[\"Job Title\"].lower() or \" soc \" in rows[\"Job Title\"].lower() or \"threat\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Cybersecurity\")\n",
    "    else :\n",
    "        short_job.append(\"Not identified\")\n",
    "\n",
    "df_5=df_4.copy()\n",
    "df_5[\"Short Job Title\"]=short_job\n",
    "df_5=df_5[df_5[\"Short Job Title\"]!=\"Not identified\"]\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_csv(\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\WebScraping101\\\\3day_glasdoor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the output\n",
    "formatted_date = now.strftime(\"%Y-%m-%d\")\n",
    "formatted_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(f\"Latest scraping date: {formatted_date}\")\n",
    "print(f\"Current time: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
