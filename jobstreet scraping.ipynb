{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_languages = [\n",
    "    \"Python\", \"JavaScript\", \"Java\", \"C#\", \"C++\", \"PHP\", \"Ruby\", \"Swift\",\n",
    "    \"Golang\", \"TypeScript\", \"R\", \"Kotlin\", \"HTML\", \"CSS\", \"SQL\", \"Rust\", \"Dart\",\n",
    "    \"Scala\", \"Perl\", \"Haskell\", \"Elixir\", \"Lua\", \"Bash\",\n",
    "    \"Objective-C\", \"Groovy\", \"F#\", \"Visual Basic\", \"MATLAB\", \"Assembly Language\",\n",
    "    \"Julia\", \"Cobol\", \"Fortran\", \"Erlang\", \"Prolog\", \"Crystal\", \"Tcl\", \"Lisp\",\n",
    "    \"ActionScript\", \"Apex\", \"Clojure\", \"Smalltalk\", \"Solidity\", \"NIM\", \n",
    "    \"OCaml\", \"Q#\", \"Ceylon\", \"VBScript\", \"Awk\", \"Racket\",\n",
    "    \"ABAP\", \"XSLT\", \"Lasso\", \"Max\", \"PostScript\", \n",
    "    \"Simulink\", \"Io\", \"Datalog\", \"Pliant\", \"J\", \"GAMS\", \"Gherkin\", \"SuperCollider\",\n",
    "    \"Sed\", \"PASCAL\"\n",
    "]\n",
    "\n",
    "for i in range(len(programming_languages)) :\n",
    "    if \".\" in programming_languages[i] :\n",
    "        programming_languages.append(programming_languages[i].replace(\".\",\"\"))\n",
    "\n",
    "databases = [\n",
    "    \"MySQL\",\n",
    "    \"PostgreSQL\",\n",
    "    \"SQLite\",\n",
    "    \"MongoDB\",\n",
    "    \"SQL Server\",\n",
    "    \"Oracle\",\n",
    "    \"Redis\",\n",
    "    \"Cassandra\",\n",
    "    \"MariaDB\",\n",
    "    \"DB2\",\n",
    "    \"Amazon DynamoDB\",\n",
    "    \"Firebase Realtime\",\n",
    "    \"Elasticsearch\",\n",
    "    \"Azure SQL\",\n",
    "    \"SAP HANA\",\n",
    "    \"CockroachDB\",\n",
    "    \"Google Cloud Firestore\",\n",
    "    \"Couchbase\",\n",
    "    \"Neo4j\",\n",
    "    \"HBase\",\n",
    "    \"Apache Hive\",\n",
    "    \"Teradata\",\n",
    "    \"Apache Cassandra\",\n",
    "    \"ArangoDB\",\n",
    "    \"RavenDB\",\n",
    "    \"Citus\",\n",
    "    \"TimescaleDB\",\n",
    "    \"OrientDB\",\n",
    "    \"Titan\",\n",
    "    \"TokuMX\",\n",
    "    \"VoltDB\",\n",
    "    \"Memcached\",\n",
    "    \"OpenTSDB\",\n",
    "    \"Dgraph\",\n",
    "    \"MarkLogic\",\n",
    "    \"Apache Drill\",\n",
    "    \"CouchDB\",\n",
    "    \"SAP IQ\",\n",
    "    \"NuoDB\",\n",
    "    \"Amazon Aurora\",\n",
    "    \"Azure Cosmos DB\",\n",
    "    \"CrateDB\",\n",
    "    \"Greenplum\",\n",
    "    \"Pivotal GemFire\",\n",
    "    \"EventStore\",\n",
    "    \"SQL Anywhere\",\n",
    "    \"DataStax Enterprise\",\n",
    "    \"AllegroGraph\",\n",
    "    \"Presto\",\n",
    "    \"Amazon Redshift\",\n",
    "    \"Informix\",\n",
    "    \"Apache Kudu\",\n",
    "    \"Sybase\",\n",
    "    \"Firebird\",\n",
    "    \"Apache Derby\",\n",
    "    \"SQLite\",\n",
    "    \"MaxDB\",\n",
    "    \"Teradata Aster\",\n",
    "    \"Vertica\",\n",
    "    \"Linterra\",\n",
    "    \"RocksDB\",\n",
    "    \"ClickHouse\",\n",
    "    \"Hadoop HDFS\",\n",
    "    \"Joomla\",\n",
    "    \"MSSQL\",\n",
    "    \"Xbase\",\n",
    "    \"Zebra\",\n",
    "    \"Wikidata\",\n",
    "    \"QlikView\",\n",
    "    \"Druid\",\n",
    "    \"Apache Phoenix\",\n",
    "    \"HSQLDB\",\n",
    "    \"Realm\",\n",
    "    \"CockroachDB\",\n",
    "    \"QLDB\",\n",
    "    \"Tarantool\",\n",
    "    \"Couchbase\",\n",
    "    \"Sphinx\",\n",
    "    \"InterBase\",\n",
    "    \"PouchDB\",\n",
    "    \"RavenDB\",\n",
    "    \"Pivotal Greenplum\",\n",
    "    \"TQL\",\n",
    "    \"Blazegraph\",\n",
    "    \"Netezza\",\n",
    "    \"Exasol\",\n",
    "    \"Coda\",\n",
    "    \"Qlik Sense\",\n",
    "    \"Linterra\",\n",
    "    \"Glean\",\n",
    "    \"OpenCensus\",\n",
    "    \"Snowflake\",\n",
    "    \"Metabase\"\n",
    "]\n",
    "for i in range(len(databases)) :\n",
    "    if \".\" in databases[i] :\n",
    "        print(databases[i])\n",
    "        databases.append(databases[i].replace(\".\",\"\"))\n",
    "\n",
    "frameworks = [\n",
    "    # Web Development\n",
    "    \"Kafka\",\n",
    "    \"SwiftUI\",\"Node.js\",\"React\", \"Angular\", \"Vue.js\", \"Django\", \"Flask\", \"Ruby on Rails\", \"Express.js\", \n",
    "    \"ASP.NET\", \"Spring\", \"Laravel\", \"Symfony\", \"FastAPI\", \"Svelte\", \"Backbone.js\", \n",
    "    \"CodeIgniter\", \"NestJS\", \"Meteor\", \"Pyramid\", \"Phoenix\", \n",
    "    \"Ionic\", \"Bootstrap\", \"Bulma\", \"Materialize\", \"Tailwind CSS\", \n",
    "    \"Ember.js\", \"Next.js\", \"Nuxt.js\", \"Gatsby\", \"Zope\", \"Sinatra\", \"JSP\", \n",
    "    \"Play Framework\", \"Tornado\", \"Web2py\", \"Sequelize\", \"Knex.js\", \"Deno\", \n",
    "    \"Sanity\", \"Strapi\", \"GraphQL\", \"RESTful API\", \"Jekyll\", \"Hugo\", \"Docusaurus\", \n",
    "    \"Aurelia\", \"Mithril\", \"Quasar\", \"Alpine.js\", \"Elm\", \"ClojureScript\", \n",
    "    \"PicoCMS\", \"Ant Design\", \"PrimeNG\", \"Semantic UI\", \"jQuery\", \n",
    "    \"Preact\", \"Turbo\", \"AppSync\", \"Flask-SocketIO\", \"Vapor\", \n",
    "    \"Jersey\", \"Vaadin\", \"Pico\", \"YII\", \"Tiki Wiki\", \"Phalcon\", \"Hapi.js\", \n",
    "    \"Koa.js\", \"Restify\", \"Slim\", \"Silex\", \"Liquid\", \"BootstrapVue\", \"Fomantic UI\", \n",
    "    \"Aurelia\", \"Chai\", \"Sass\", \"PostCSS\", \"jQuery UI\", \"Kendo UI\", \n",
    "    \"Dojo\", \"Webix\", \"Gijgo\", \"Pikaday\", \"FullCalendar\", \"Handsontable\", \n",
    "    \"GrapeJS\", \"Frappe\", \"Phabricator\", \"CakePHP\", \"Nette\", \"Yii2\", \"SilverStripe\", \n",
    "    \"OroCRM\", \"TYPO3\", \"CouchCMS\", \"Concrete5\", \"Grav\", \"Kirby\", \"OctoberCMS\", \n",
    "    \"ProcessWire\", \"MODX\", \"Craft CMS\", \"Pimcore\", \"Bolt\", \"Umbraco\", \"DotNetNuke\",\n",
    "\n",
    "    # Mobile Development\n",
    "    \"React Native\", \"Flutter\", \"Xamarin\", \"Ionic\", \"Apache Cordova\", \"USwiftI\", \n",
    "    \"Kotlin Multiplatform Mobile\", \"PhoneGap\", \"NativeScript\", \"Sencha Touch\", \n",
    "    \"Appcelerator Titanium\", \"Framework7\", \"Unity\", \"Cocos2d-x\", \"Fusetools\", \n",
    "    \"NativeBase\", \"Quasar Framework\", \"Onsen UI\", \"Cordova\", \"ReactXP\", \n",
    "    \"Tauri\", \"Kivy\", \"PyQt5\", \"wxPython\", \"BeeWare\", \"Gluon\", \"Crosswalk\", \n",
    "    \"Fyn\", \"Material Components for Android\", \"Robolectric\", \"Apache Felix\", \n",
    "    \"Zygote\", \"UI Automator\", \"MonkeyRunner\", \"Firebase UI\", \"Codename One\", \n",
    "    \"Nativescript-Vue\", \"RxJava\", \"Dagger\", \"ButterKnife\", \"Retrofit\", \"Volley\", \n",
    "    \"OkHttp\", \"RxAndroid\", \"Firebase Cloud Messaging\", \"Fastlane\", \"Swift Package Manager\",\n",
    "\n",
    "    # Game Development\n",
    "    \"Unity\", \"Unreal Engine\", \"Godot\", \"Cocos2d\", \"CryEngine\", \"GameMaker Studio\", \n",
    "    \"Phaser\", \"LibGDX\", \"Defold\", \"Ren'Py\", \"SpriteKit\", \"Cocos2d-x\", \n",
    "    \"Pygame\", \"MonoGame\", \"JMonkeyEngine\", \"GameSalad\", \"Havok\", \"Fmod\", \"Unity3D\", \n",
    "    \"CryEngine\", \"Torque3D\", \"PlayCanvas\", \"Blend4Web\", \"Panda3D\", \"CopperLicht\", \n",
    "    \"Ogre3D\", \"Three.js\", \"Babylon.js\", \"Fusio\", \"LÖVE\", \"BGE\", \"Cinder\", \n",
    "    \"Game Framework\", \"Wave Engine\", \"PICO-8\", \"Phaser Editor\", \"GDevelop\", \n",
    "    \"Cocos Creator\", \"Chocolat\", \"Bevy\", \"Flixel\", \"Luxe\", \"Leadwerks\", \n",
    "    \"Allegro\", \"GML\", \"Squirrel\", \"Visual3D\", \"Sunburn\", \"C4\", \"Zenject\",\n",
    "\n",
    "    # Data Science and Machine Learning\n",
    "    \"PySpark\",\"Tensorflow\", \"Keras\", \"PyTorch\", \"Scikit\", \"Pandas\", \"NumPy\", \n",
    "    \"Matplotlib\", \"Seaborn\", \"Spark\", \"Dask\", \"H2O.ai\", \"Apache Flink\", \n",
    "    \"Hadoop\", \"OpenCV\", \"NLTK\", \"spaCy\", \"FastAI\", \"XGBoost\", \"LightGBM\", \n",
    "    \"CatBoost\", \"MLflow\", \"Airflow\", \"PyCaret\", \"Dask-ML\", \"Haystack\", \n",
    "    \"Shiny\", \"Dash\", \"Plotly\", \"Streamlit\", \"Bokeh\", \"TensorBoard\", \n",
    "    \"Chainer\", \"Pytorch Lightning\", \"TPOT\", \"DataRobot\", \"AutoML\", \"TPOT\", \n",
    "    \"Optuna\", \"Ray\", \"FastText\", \"gensim\", \"Featuretools\", \"Weka\", \n",
    "    \"KNIME\", \"Alteryx\", \"Datarobot\", \"Metaflow\", \"Jupyter Notebook\", \n",
    "     \"Dash\", \"Orange3\", \"DeepSpeed\", \"Fairlearn\", \"FiftyOne\",\n",
    "\n",
    "    # DevOps and CI/CD\n",
    "     \"Babel\",\"Vite\",\"Parcel\",\"Webpack\",\"Grunt\",\n",
    "\n",
    "    # Testing Frameworks\n",
    "    \"JUnit\", \"pytest\", \"Selenium\", \"Mocha\", \"Chai\", \"Jasmine\", \"Cypress\", \n",
    "    \"TestNG\", \"RSpec\", \"Jest\", \"Karma\", \"Puppeteer\", \"Robot Framework\", \n",
    "    \"Protractor\", \"Postman\", \"Cucumber\", \"JUnit\", \"NUnit\", \"Vitest\", \n",
    "    \"Enzyme\", \"Cypress\", \"Supertest\", \"Mocha\", \"Mochawesome\", \"Pytest-bdd\", \n",
    "    \"Gatling\", \"Locust\", \"Trestle\", \"Avro\", \"WireMock\", \"Karate\", \n",
    "    \"Selenium Grid\", \"Applitools\", \"Gauge\", \"Cypress\", \"RestAssured\", \n",
    "    \"Flask-Testing\", \"Flask-RESTPlus\", \"Playwright\", \"SpecFlow\", \"Codacy\", \n",
    "    \"SonarQube\", \"Selenium IDE\",\n",
    "\n",
    "    # Desktop Applications\n",
    "    \"Electron\", \"Qt\", \"GTK\", \"JavaFX\", \"wxWidgets\", \"Avalonia\", \"Flutter Desktop\", \n",
    "    \"Nw.js\", \"Xamarin.Forms\", \"React Native Windows\", \"Tauri\", \"Electron Forge\", \n",
    "    \"PyQt\", \"Tkinter\", \"Kivy\", \"PySide\", \"WinForms\", \"MFC\", \"GTK\", \"UWP\", \n",
    "    \"Avalonia UI\", \"JavaFX\", \"Flutter\", \"Blazor\", \"Uno Platform\", \"WPF\", \n",
    "    \"Chocolat\", \"AppKit\", \"Mac Catalyst\", \"PyQt5\", \"Gnome\", \"Electron React\", \n",
    "    \"Cocoa\", \"Xamarin\", \"Delphi\", \"Qt Creator\", \"QT Quick\", \"Swing\", \n",
    "    \"Java Swing\", \"Pygame\", \"Avalonia\", \"VCL\",\n",
    "\n",
    "    # Other Frameworks and Libraries\n",
    "\n",
    "    \"FAIR\",\"KOBIT\", \"RabbitMQ\", \"Celery\", \"OpenShift\", \"Nginx\", \"Apache HTTP Server\" , \"SendGrid\", \"Twilio\", \"Stripe\", \"Socket.io\", \n",
    "    \"GraphQL\", \"gRPC\", \"Pusher\", \"Flask-RESTful\", \n",
    "    \"Jupyter Notebook\", \"Apache Thrift\", \"Hapi.js\", \"React Query\", \"Apollo Client\", \n",
    "    \"WebAssembly\", \"RxJS\", \"Flux\", \"MobX\", \"Gulp\", \"Webpack\", \"Parcel\", \n",
    "    \"Babel\", \"Grunt\", \"Vite\", \"Puppeteer\", \"Sass\", \"PostCSS\", \"Frappe\", \"Django REST Framework\", \"Netty\", \n",
    "    \"Spring Boot\", \"Play Framework\", \"Dropwizard\", \"Java EE\", \"Vaadin\", \n",
    "    \"Grails\", \"Avert\", \"Flyway\", \"JOOQ\", \"Spring Data\", \"MicroProfile\", \n",
    "    \"Ktor\", \"Vert.x\", \"Gson\", \"Jackson\", \"jOOQ\", \"Apache Ant\", \"Jenkins\", \n",
    "    \"Concourse\", \"Mercurial\", \"Bazaar\", \n",
    "    \"TFS\", \"Subversion\", \"Plastic SCM\", \"FogBugz\", \"Phabricator\", \"Helix Core\", \n",
    "    \"Gitea\", \"Gogs\", \"SourceGear Vault\", \"SmartSVN\", \"TortoiseSVN\", \n",
    "    \"Fossil\", \"SVN\", \"Aegis\",\n",
    "\n",
    "    # Additional Frameworks\n",
    "    \"ISO 27001\",\n",
    "\"MITRE ATT\",\n",
    "\"COBIT\",\n",
    "\"PCI DSS\",\n",
    "\"SOC 2\",\n",
    "\"GDPR\",\n",
    "\"ITIL\",\n",
    "\"CMMI\",\n",
    "\"Cis Controls\",\n",
    "    \"Spring Cloud\", \"Spring Security\", \"Spring MVC\", \"Spring Integration\", \n",
    "    \"Spring Batch\", \"Apache Camel\", \"Apache Shiro\", \"Canoe\", \"Libuv\", \n",
    "    \"ASP.NET MVC\", \"ASP.NET Core\", \"Apache Cordova\", \"Xamarin\", \"OSGi\", \n",
    "    \"React Query\", \"SWR\", \"Apollo Client\", \"Puppeteer\", \"Cheerio\", \n",
    "    \"Bootstrap\", \"Fomantic UI\", \"Materialize\", \"PrimeReact\", \n",
    "    \"Ant Design\", \"Semantic UI\", \"Spectre.css\", \"UIKit\", \"Material Design Lite\", \n",
    "    \"Milligram\", \"Skeleton\", \"Blaze UI\", \"Fomantic UI\", \"Semantic UI React\", \n",
    "    \"Stylus\", \"Foundation Sites\", \"HTML5 Boilerplate\", \"Normalize.css\", \n",
    "    \"PostCSS\", \"CSS Modules\", \"CSS-in-JS\", \"Styled Components\", \n",
    "    \"Emotion\", \"JSS\", \"Radium\", \"Shadow DOM\", \"LitElement\", \"HyperHTML\", \n",
    "    \"html.js\", \"Gatsby\", \"Next.js\", \"Nuxt.js\", \"Hugo\", \"Jekyll\", \"Docusaurus\", \n",
    "    \"Scully\", \"Sapper\", \"Gatsby\", \"Middleman\", \"Grunt\", \"Gulp\", \"npm\", \n",
    "    \"Yarn\", \"Webpack\", \"Parcel\", \"Vite\", \"Fly\", \"Zola\", \"Ziggy\", \"TiddlyWiki\", \n",
    "    \"Sphinx\", \"MkDocs\", \"Doxygen\", \"HDoc\", \"Doxygen\", \n",
    "    \"Javadoc\", \"Sphinx\", \"Hugo\", \"Jekyll\", \"MkDocs\"\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(len(frameworks)) :\n",
    "    if \".\" in frameworks[i] :\n",
    "        frameworks.append(frameworks[i].replace(\".\",\"\"))\n",
    "\n",
    "\n",
    "cloud_service_providers = [\n",
    "    \"Bigquery\",\n",
    "    \"Redshift\",\n",
    "    \"Databricks\",\n",
    "    \"AWS\",\n",
    "    \"Azure\",\n",
    "    \"GCP\",\n",
    "    \"IBM Cloud\",\n",
    "    \"Oracle Cloud\",\n",
    "    \"Salesforce\",\n",
    "    \"DigitalOcean\",\n",
    "    \"Linode\",\n",
    "    \"Vultr\",\n",
    "    \"Heroku\",\n",
    "    \"Rackspace\",\n",
    "    \"Cloudflare\",\n",
    "    \"Red Hat OpenShift\",\n",
    "    \"SAP Cloud Platform\",\n",
    "    \"Alibaba Cloud\",\n",
    "    \"Mendix\",\n",
    "    \"Cisco Cloud\",\n",
    "    \"Cloudways\",\n",
    "    \"Trello\",\n",
    "    \"Zoho\",\n",
    "    \"Atlassian Cloud\",\n",
    "    \"Smartsheet\",\n",
    "    \"Firebase\",\n",
    "    \"Contentful\",\n",
    "    \"Shopify\",\n",
    "    \"Zendesk\",\n",
    "    \"Fastly\",\n",
    "    \"Akamai\",\n",
    "    \"SiteGround\",\n",
    "    \"InMotion Hosting\",\n",
    "    \"WP Engine\",\n",
    "    \"GreenGeeks\",\n",
    "    \"A2 Hosting\",\n",
    "    \"HostGator\",\n",
    "    \"iPage\",\n",
    "    \"Bluehost\",\n",
    "    \"Liquid Web\",\n",
    "    \"DreamHost\",\n",
    "    \"Kinsta\",\n",
    "    \"CloudSigma\",\n",
    "    \"OVHcloud\",\n",
    "    \"CenturyLink Cloud\",\n",
    "    \"Gandi\",\n",
    "    \"Google Workspace\",\n",
    "    \"Microsoft 365\",\n",
    "    \"MaxCompute\",\n",
    "    \"Clever Cloud\",\n",
    "    \"Render\",\n",
    "    \"Platform.sh\",\n",
    "    \"Back4App\",\n",
    "    \"Kinvey\",\n",
    "    \"GCP Firebase\",\n",
    "    \"Bitbucket\",\n",
    "    \"Vercel\",\n",
    "    \"Netlify\",\n",
    "    \"Glitch\",\n",
    "    \"Heroku Postgres\",\n",
    "    \"Linode Block Storage\",\n",
    "    \"Cloudian\",\n",
    "    \"Pivotal Cloud Foundry\",\n",
    "    \"Couchbase Cloud\",\n",
    "    \"MongoDB Atlas\",\n",
    "    \"BaaS\",\n",
    "    \"Auth0\",\n",
    "    \"Cloudflare Workers\",\n",
    "    \"Kinsta Managed WordPress Hosting\",\n",
    "    \"Elastic Cloud\",\n",
    "    \"Integromat\",\n",
    "    \"Zapier\",\n",
    "    \"Cognito\",\n",
    "    \"S3\",\n",
    "    \"Oracle Cloud Infrastructure\",\n",
    "    \"IBM Watson\",\n",
    "    \"Azure DevOps\",\n",
    "    \"CloudStack\",\n",
    "    \"OpenStack\",\n",
    "    \"Scaleway\",\n",
    "    \"Jelastic\",\n",
    "    \"Backblaze B2\",\n",
    "    \"Linode Kubernetes Engine\",\n",
    "    \"Miro\",\n",
    "    \"Airtable\",\n",
    "    \"Quip\",\n",
    "    \"SurveyMonkey\",\n",
    "    \"Slack\",\n",
    "    \"Sentry\",\n",
    "    \"AppDynamics\",\n",
    "    \"New Relic\",\n",
    "    \"Grafana Cloud\",\n",
    "    \"Prometheus\",\n",
    "    \"CloudHealth\",\n",
    "    \"SaaSOptics\",\n",
    "    \"Zoho One\",\n",
    "    \"FreshBooks\",\n",
    "    \"Xero\",\n",
    "    \"QuickBooks Online\",\n",
    "    \"Wix\",\n",
    "    \"Webflow\",\n",
    "    \"Shopify Plus\",\n",
    "    \"BigCommerce\",\n",
    "    \"Adobe Experience Cloud\",\n",
    "    \"Veeva Vault\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "other_tools = [\n",
    "    \"Owasp\",\n",
    "    \"Zscaler\", \n",
    "    \"CrowdStrike\", \n",
    "    \"Rapid7\", \n",
    "    \"Defender VM\", \n",
    "    \"Qualys\", \n",
    "    \"Tenable\", \n",
    "    \"Nessus\", \n",
    "    \"Auth0\", \n",
    "    \"PingID\", \n",
    "    \"Azure AD\", \n",
    "    \"Okta\",\n",
    "    \"Cisco\",\"SSIS\",\n",
    "    \"Ansible\", \"Terraform\", \"Jenkins\", \"CircleCI\", \n",
    "    \"Travis CI\", \"GitLab CI\", \"AWS CodePipeline\", \"Chef\", \n",
    "    \"Puppet\", \"Octopus Deploy\", \"Helm\", \"Grafana\", \"Nagios\", \n",
    "    \"Datadog\", \"ELK Stack\", \"Kibana\", \n",
    "    \"GitHub Actions\", \"AppVeyor\", \"Codacy\", \"Tecton\", \"LaunchDarkly\", \n",
    "    \"Semaphore\", \"GitKraken\", \"Azure DevOps Server\", \"GitHub Pages\", \"Render\", \"Fly.io\", \n",
    "    \"Railway\", \"npm\", \"Yarn\", \"Composer\", \"Bower\", \"Gulp\", \n",
    "    \"Webpack\", \"Parcel\", \"Babel\", \"Grunt\", \"Vite\", \"Sentry\", \"SonarQube\",\"Kubernetes\",\"CVS\",\"Wordpress\",\"Apache Superset\",'SAS','Docker','QRadar', 'Securonix',\n",
    "       'Checkpoint', 'FireEye', 'ArcSight',\n",
    "       'NIST Cybersecurity Framework', 'Nessus', 'Wireshark',\n",
    "       'Palo Alto Networks', 'Burp Suite', 'Kali Linux', 'Trend Micro',\n",
    "       'Sophos', 'Responder', 'Metasploit', 'Nmap', 'Cisco ASA',\n",
    "    \"Qualys\",\n",
    "    \"Splunk\",\n",
    "    \"DataStage\",\n",
    "    \"spotfire\",\n",
    "    \"sap\",\n",
    "    \"Git\",\n",
    "    \"Office Suite\",\n",
    "    \"Trello\",\n",
    "    \"Asana\",\n",
    "    \"Jira\",\n",
    "    \"Confluence\",\n",
    "    \"Zoom\",\n",
    "    \"Adobe Creative Cloud\",\n",
    "    \"Figma\",\n",
    "    \"Canva\",\n",
    "    \"Miro\",\n",
    "    \"Power BI\",\n",
    "    \"Notion\",\n",
    "    \"Monday.com\",\n",
    "    \"Dropbox\",\n",
    "    \"Box\",\n",
    "    \"SharePoint\",\n",
    "    \"Evernote\",\n",
    "    \"GitHub\",\n",
    "    \"HubSpot\",\n",
    "    \"Mailchimp\",\n",
    "    \"Zapier\",\n",
    "    \"QuickBooks\",\n",
    "    \"Toggl\",\n",
    "    \"LastPass\",\n",
    "    \"Tableau\",\n",
    "    \"Google Analytics\",\n",
    "    \"SEMrush\",\n",
    "    \"JotForm\",\n",
    "    \"Basecamp\",\n",
    "    \"ClickUp\",\n",
    "    \"InVision\",\n",
    "    \"Lucidchart\",\n",
    "    \"Visio\",\n",
    "    \"PowerPoint\",\n",
    "    \"Google Slides\",\n",
    "    \"Balsamiq\",\n",
    "    \"MindMeister\",\n",
    "    \"XMind\",\n",
    "    \"Calendly\",\n",
    "    \"RescueTime\",\n",
    "    \"Adobe Acrobat\",\n",
    "    \"Mendeley\",\n",
    "    \"EndNote\",\n",
    "    \"Excel\",\n",
    "    \"Adobe Analytics\",\n",
    "    \"Looker\",\n",
    "    \"Adobe Creative Suite\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(i,word_array):\n",
    "  try:\n",
    "    for j in range (i-5,i):\n",
    "        if word_array[j]== \"year\" or word_array[j]==\"years\":\n",
    "          return j\n",
    "  except:\n",
    "    return -1\n",
    "\n",
    "  return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "  word_array = text.split()\n",
    "  for i in range(len(word_array)) :\n",
    "    if word_array[i] == \"experience\" or word_array[i]==\"experiences\":\n",
    "      j=in_range(i,word_array)\n",
    "      if j != -1:\n",
    "        return word_array[j-1]\n",
    "  return \"Not_specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text,skillset):\n",
    "    skills = []\n",
    "    for i in skillset :\n",
    "      if i.lower() in text.lower():\n",
    "        skills.append(i)\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_extractor(i,programming_languages,frameworks,databases,cloud_service_providers,other_tools,job_requirements,experiences):\n",
    "  # Load the HTML content\n",
    "  with open(f'C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_{i}.html', 'r', encoding='utf-8') as file:\n",
    "      html_content = file.read()\n",
    "\n",
    "  soup = BeautifulSoup(html_content, 'lxml')\n",
    "  skills = programming_languages + frameworks + databases + cloud_service_providers + other_tools\n",
    "  skills = list(set(skills))\n",
    "  \n",
    "  for i in range (len(skills)) :\n",
    "    if len(skills[i])<=10:\n",
    "      skills[i]=\" \"+skills[i]+\" \"\n",
    "\n",
    "  text_array = []\n",
    "  li_tags = soup.find_all('li', class_=False)\n",
    "  p_tags = soup.find_all('p',class_=False)\n",
    "\n",
    "  for i in li_tags:\n",
    "    text_array.append(i.text)\n",
    "\n",
    "  for i in p_tags :\n",
    "    text_array.append(i.text)\n",
    "\n",
    "  concatenated_string = \" \".join(text_array)\n",
    "\n",
    "  concatenated_string = \" \"+concatenated_string+\" \"\n",
    "  concatenated_string = re.sub(r'(?<![A-Za-z0-9])\\.|\\.(?![A-Za-z0-9])|[^A-Za-z0-9.#+]', ' ', concatenated_string)\n",
    "\n",
    "  #print(concatenated_string)\n",
    "  #print(extract_skills(concatenated_string,skills))\n",
    "\n",
    "  job_requirements.append(concatenated_string)\n",
    "  experiences.append(extract_experience(concatenated_string))\n",
    "\n",
    "\n",
    "  return (extract_skills(concatenated_string,skills))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = \"C:\\\\Users\\\\ahmad\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-21nov24\\\\chromedriver.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=driver_path)\n",
    "\n",
    "wd = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=3\n",
    "base_url=[\n",
    "    f\"https://my.jobstreet.com/data-analyst-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/data-scientist-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/data-engineer-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/business-analyst-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/front-end-developer-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/back-end-developer-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/full-stack-developer-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/cloud-engineer-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/cybersecurty-jobs?daterange={days}\",\n",
    "    f\"https://my.jobstreet.com/software-engineer-jobs?daterange={days}\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes=[]\n",
    "for b in range(len(base_url)):\n",
    "    #approximate number of pages available\n",
    "    wd.get(base_url[b])\n",
    "    with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_jobstreet.html\", \"w\") as file:\n",
    "            file.write(wd.page_source)\n",
    "    with open(f'C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\test_jobstreet.html', 'r', encoding='utf-8') as file:\n",
    "            html_content_zz = file.read()\n",
    "            \n",
    "    soup = BeautifulSoup(html_content_zz, 'lxml')\n",
    "\n",
    "    # Find the job count element\n",
    "    job_count = soup.find('span', {'data-automation': 'totalJobsCount'})\n",
    "\n",
    "    job_count_value = job_count.text\n",
    "    job_count_value = int(job_count.text.replace(',', ''))\n",
    "    page_count =int(job_count_value/32)\n",
    "    if page_count <=1:\n",
    "         page_count = 2\n",
    "    print(\"Job Count : \",job_count_value)\n",
    "    print(\"Page Count : \",page_count)\n",
    "\n",
    "\n",
    "    job_dataframes=[]\n",
    "    a=0\n",
    "    for i in range (1,page_count):\n",
    "        \n",
    "\n",
    "        wd.get(base_url[b]+f\"&page={i}\")\n",
    "        time.sleep(2.5)\n",
    "        with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\{i}.html\", \"w\") as file:\n",
    "            file.write(wd.page_source)\n",
    "\n",
    "        with open(f'C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\{i}.html', 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "\n",
    "        articles = soup.find_all('article')\n",
    "        \n",
    "\n",
    "        job_ids = [] \n",
    "        job_titles = []\n",
    "        company_names = []\n",
    "        job_locations = []\n",
    "        job_salaries = []\n",
    "        job_types = []\n",
    "        job_descriptions = []\n",
    "        page=[]\n",
    "        skills=[]\n",
    "        year_of_experiences=[]\n",
    "        job_requirements=[]\n",
    "\n",
    "\n",
    "\n",
    "        # Loop through each article and extract relevant information\n",
    "        \n",
    "        for article in articles:\n",
    "            page.append(i)\n",
    "            page_latest = i\n",
    "\n",
    "\n",
    "            # Extract job ID (Assuming it is in a data attribute)\n",
    "            job_id = article['data-job-id'] if 'data-job-id' in article.attrs else 'N/A'\n",
    "            job_ids.append(job_id)\n",
    "            job_latest = job_id\n",
    "\n",
    "            # Extract job title\n",
    "            job_title = article.find('a', {'data-automation': 'jobTitle'}).text.strip() if article.find('a', {'data-automation': 'jobTitle'}) else 'N/A'\n",
    "            job_titles.append(job_title)\n",
    "\n",
    "            # Extract company name\n",
    "            company_name = article.find('a', {'data-automation': 'jobCompany'}).text.strip() if article.find('a', {'data-automation': 'jobCompany'}) else 'N/A'\n",
    "            company_names.append(company_name)\n",
    "\n",
    "        \n",
    "\n",
    "            # Extract job location\n",
    "            job_location = article.find('span', {'data-automation': 'jobCardLocation'}).text.strip() if article.find('span', {'data-automation': 'jobCardLocation'}) else 'N/A'\n",
    "            job_locations.append(job_location)\n",
    "\n",
    "            # Extract job salary\n",
    "            job_salary = article.find('span', {'data-automation': 'jobSalary'}).text.strip() if article.find('span', {'data-automation': 'jobSalary'}) else 'N/A'\n",
    "            job_salaries.append(job_salary)\n",
    "\n",
    "            # Extract job type\n",
    "            job_type = article.find('p').text.strip() if article.find('p') else 'N/A'  # Assuming this is the job type\n",
    "            job_types.append(job_type)\n",
    "\n",
    "            # Extract job description (if available)\n",
    "            job_description = article.find('div', {'class': 'nbwpkd6u'}).text.strip() if article.find('div', {'class': 'nbwpkd6u'}) else 'N/A'  # Adjust class name as necessary\n",
    "            job_descriptions.append(job_description)\n",
    "\n",
    "        \n",
    "            skip=False\n",
    "            j=0\n",
    "            while(True):\n",
    "                if j>2:\n",
    "                    skip=True\n",
    "                    j=0\n",
    "                    break\n",
    "                try:\n",
    "                    if page_latest==1:\n",
    "                        wd.get(base_url[b]+f\"&jobId={job_latest}&type=standout\")\n",
    "                    else:\n",
    "                        wd.get(base_url[b]+f\"&page={page_latest}&jobId={job_latest}&type=standout\")\n",
    "                    time.sleep(2.5)\n",
    "                    with open(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_{a+1}.html\", \"w\") as file:\n",
    "                        file.write(wd.page_source)\n",
    "                    break\n",
    "\n",
    "                except:\n",
    "                    print(\"something is wrong with the webpage with job_id = \",job_latest)\n",
    "                    time.sleep(2.5)\n",
    "                    j=j+1\n",
    "                    \n",
    "            if(skip==True):\n",
    "                job_requirements.append(\"error\")\n",
    "                skills.append(\"error\")\n",
    "                year_of_experiences.append(\"error\")\n",
    "                wd.quit()\n",
    "                wd = webdriver.Chrome(service=service)\n",
    "                continue\n",
    "\n",
    "            skills.append(skill_extractor(a+1,programming_languages,frameworks,databases,cloud_service_providers,other_tools,job_requirements,year_of_experiences))\n",
    "      \n",
    "\n",
    "            if os.path.exists(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_{a+1}.html\"):\n",
    "                os.remove(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\subpages\\\\subpage_{a+1}.html\")\n",
    "                print(f\"{a+1} files has been scraped\")\n",
    "            else:\n",
    "                print(\"idk bro\")\n",
    "\n",
    "            a=a+1\n",
    "\n",
    "\n",
    "        # Create a DataFrame from the lists\n",
    "\n",
    "        job_data = pd.DataFrame({\n",
    "            'Job ID': job_ids,\n",
    "            'Job Title': job_titles,\n",
    "            'Company Name': company_names,\n",
    "            'Location': job_locations,\n",
    "            'Salary': job_salaries,\n",
    "            'Job Type': job_types,\n",
    "            'Description': job_descriptions,\n",
    "            'Page':page,\n",
    "            'Job Requirements':job_requirements,\n",
    "            'Skills':skills,\n",
    "            'Years Of Experience':year_of_experiences\n",
    "\n",
    "        })\n",
    "        print(job_data.head())\n",
    "\n",
    "        job_dataframes.append(job_data)\n",
    "\n",
    "        if os.path.exists(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\{i}.html\"):\n",
    "                os.remove(f\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\\\html_scripts\\\\{i}.html\")\n",
    "                print(f\"page {i} has been scraped\")\n",
    "        else:\n",
    "            print(\"idk bro\")\n",
    "\n",
    "\n",
    "\n",
    "    final_df = pd.concat(job_dataframes)\n",
    "    dataframes.append(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if code crashes\n",
    "'''\n",
    "final_df_filtered = final_df.copy()\n",
    "final_df_filtered = final_df_filtered.head(1130)\n",
    "final_df_filtered[\"Job Requirements\"]=job_requirements\n",
    "final_df_filtered[\"Skills\"]=skills\n",
    "final_df_filtered[\"Years Of Experience\"]=year_of_experiences\n",
    "\n",
    "final_df_2 = final_df_filtered.copy()\n",
    "\n",
    "Y_O_E_updated =[]\n",
    "\n",
    "i=0\n",
    "for rows in final_df_2[\"Years Of Experience\"]:\n",
    "    if \"intern\" in final_df_2.iloc[i][\"Job Title\"].lower():\n",
    "        Y_O_E_updated.append(\"Internship\")\n",
    "    else :\n",
    "        Y_O_E_updated.append(rows)\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "final_df_2[\"Years Of Experience\"]=Y_O_E_updated\n",
    "\n",
    "final_df_2.to_csv(\"first 315 to 1446rows data_analyst_jobs\",index=False)\n",
    "'''\n",
    "final_df=pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(final_df['Job ID'].unique()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_1 = final_df.copy()\n",
    "\n",
    "Y_O_E_updated =[]\n",
    "\n",
    "i=0\n",
    "for rows in df_1[\"Years Of Experience\"]:\n",
    "    if \"intern\" in df_1.iloc[i][\"Job Title\"].lower():\n",
    "        Y_O_E_updated.append(\"Internship\")\n",
    "    else :\n",
    "        Y_O_E_updated.append(rows)\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "df_1[\"Years Of Experience\"]=Y_O_E_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.quit()\n",
    "#final_df_1.to_csv(\"jobStreet_fullstack_developer.csv\",index=False)\n",
    "#final_df_1.to_csv(\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\Documents\\\\Job Csv Files\\\\jobStreet_fullstack_developer_jobs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates with errors\n",
    "def has_dup(job_id):\n",
    "    return df_1[\"Job ID\"].value_counts().get(job_id, 0) > 1\n",
    "\n",
    "def det_condition(rows):\n",
    "    if(has_dup(rows[\"Job ID\"]) and len(rows[\"Job Requirements\"])<6):\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "df_1['condition']=df_1.apply(det_condition,axis=1)\n",
    "df_1=df_1[df_1['condition']==False]\n",
    "df_1.drop(columns = [\"condition\"],inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove actual duplicates\n",
    "df_2 = df_1.copy()\n",
    "df_2.drop_duplicates(subset=[\"Job ID\"],inplace=True)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_job=[]\n",
    "for index,rows in df_3.iterrows():\n",
    "    if \"data\" in rows[\"Job Title\"].lower() and \"scien\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Scientist\")\n",
    "    elif \"business\" in rows[\"Job Title\"].lower() and (\"anal\" in rows[\"Job Title\"].lower() or \"intell\" in rows[\"Job Title\"].lower()):\n",
    "        short_job.append(\"Business Analyst\")\n",
    "    elif \"data\" in rows[\"Job Title\"].lower() and \"engine\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Engineer\")\n",
    "    elif \"data\" in rows[\"Job Title\"].lower() and \"anal\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Analyst\")\n",
    "    elif \"machine\" in rows[\"Job Title\"].lower() and \"learn\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Data Scientist\")\n",
    "    elif \"full\" in rows[\"Job Title\"].lower() and \"stack\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append('Full Stack Developer')\n",
    "    elif \"back\" in rows[\"Job Title\"].lower() and \"end\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Backend Developer\")\n",
    "    elif \"front\" in rows[\"Job Title\"].lower() and \"end\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Frontend Developer\")\n",
    "    elif \"software\" in rows[\"Job Title\"].lower() and (\"engine\" in rows[\"Job Title\"].lower() or \"develop\" in rows[\"Job Title\"].lower()):\n",
    "        short_job.append(\"Developer\")\n",
    "    elif \"developer\" in rows[\"Job Title\"].lower() or \"programmer\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Developer\")\n",
    "    elif \"cloud\" in rows[\"Job Title\"].lower() or \"devop\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Cloud Engineer\")\n",
    "    elif \"secu\" in rows[\"Job Title\"].lower() or \" soc \" in rows[\"Job Title\"].lower() or \"threat\" in rows[\"Job Title\"].lower():\n",
    "        short_job.append(\"Cybersecurity\")\n",
    "    else :\n",
    "        short_job.append(\"Not identified\")\n",
    "\n",
    "\n",
    "df_3[\"Short Job Title\"]=short_job\n",
    "df_3=df_3[df_3[\"Short Job Title\"]!=\"Not identified\"]\n",
    "df_3\n",
    "#df_temp = df_3[df_3[\"Short Job Title\"]==\"Developer\"]\n",
    "#df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"C:\\\\Users\\\\ahmad\\\\OneDrive\\\\文档\\WebScraping101\\\\3day_jobstreet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the output\n",
    "formatted_date = now.strftime(\"%Y-%m-%d\")\n",
    "formatted_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(f\"Latest scraping date: {formatted_date}\")\n",
    "print(f\"Current time: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
